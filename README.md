# AI_prompt
LLM_prompt 首先测试了zero-shot和n-shot作为baseline，根据论文复现了self-polish、Program of Thoughts Prompting(POE)，并且设计了一种新模型问答架构![image](https://github.com/user-attachments/assets/0baaab2d-f7ca-4838-a8f0-de831ded59f0)![image](https://github.com/user-attachments/assets/886db4ad-b94d-4de8-b6e3-ebf9740d4f44)
prompt_diversity 测试了不同prompt的变体对模型效果的影响，比如prompt的质量、复杂度、示例数量、多样性等。有多个发现，比如示例的数量并不是越多越好，如图所示。<img width="566" alt="image" src="https://github.com/user-attachments/assets/2f051798-65a1-48c9-a2a4-873149c84e26" />

